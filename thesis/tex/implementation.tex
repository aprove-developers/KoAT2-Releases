\section{Implementation}

We developed a prototype which implements the search for time, size and cost bounds.
This implementation focuses on high modularity and maintainability, but uses optimized procedures in performance relevant parts of the program.
The tool is implemented with the ML-derived language OCaml.
This chapter gives an overview of the implementation.

\subsection{Preprocessors}

The implementation uses several common preprocessors.
A preprocessor is a function $p: 2^{\LSet \times \TSet} \rightarrow 2^{\LSet \times \TSet}$ which maps a program to an equivalent program.
We say that a preprocessor $p$ changes a program $\Program = ((\LSet, \TSet), \location_0, \VSet, \cost)$ iff $p(\Program) \neq \Program$.
We say that a preprocessor $p_1$ affects another preprocessor $p_2$ iff there are programs $\Program = ((\LSet, \TSet), \location_0, \VSet, \cost)$ such that $p_2(\Program) = \Program$, but $p_2$ changes the preprocessed program $p_1(\Program)$, e.g. $p_2(p_1(\Program)) \neq p_1(\Program)$.

We provide two different execution strategies.
The trivial execution strategy executes a given sequence of preprocessors $p_1, \dots, p_n$.
The second execution strategy is a work-list algorithm, which executes every preprocessor and appends all affected preprocessors to the work-list if a preprocessor changed the program.

We define three common preprocessors $p_{\text{reachable}}$, $p_{\text{sat}}$ and $p_{\text{invgen}}$.

\subsubsection{Removal of unreachable locations}

The preprocessor $p_{\text{reachable}}$ removes all locations, which are unreachable from the start location.
To achieve that, the preprocessor follows the transitions of the graph and marks each visited location, adding them to a set $\LSet'$.
The set of locations $\LSet \setminus \LSet'$ is then the set of all unreachable locations.
The result of the preprocessor is a program $((\LSet', \TSet'), \location_0, \VSet, \cost)$, where $\TSet' = \braced{(\location,\update,\guard,\location') \mid \exists (\location,\update,\guard,\location') \in \TSet: \location \in \LSet' \wedge \location' \in \LSet'}$ is the set of transitions whose start and end locations are both in the reachable set $\LSet'$.

The preprocessor $p_{\text{reachable}}$ does not affect any defined preprocessor.

\subsubsection{Removal of unsatisfiable transitions}

The preprocessor $p_{\text{sat}}$ removes transitions which conditions are unsatisfiable.
The result of the preprocessor is a program $((\LSet, \TSet'), \location_0, \VSet, \cost)$, where $\TSet' = \braced{(\location,\update,\guard,\location') \mid \exists (\location,\update,\guard,\location') \in \TSet: \neg (\bigwedge \guard \models \emptyset)}$ is the set of all satisfiable transitions.

The preprocessor $p_{\text{sat}}$ affects the preprocessors $p_{\text{reachable}}$.
The preprocessor $p_{\text{reachable}}$ is affected in a scenario $\Program = ((\braced{\location_0, \location_1}, \braced{(\location_0,\update,\text{false},\location_1)}), \location_0, \emptyset, \cost)$.
In this example the transition $(\location_0,\update,\text{false},\location_1)$ will be removed by $p_{\text{sat}}$.
This leaves the location $\location_1$ unreachable.

\subsubsection{Invariant generation}

The preprocessor $p_{\text{invgen}}$ generates invariants and adds them to the designated transitions.
This way it makes implicit information explicit and available for local analyses.
It uses the APRON library \cite{apron}.
The APRON library is an abstract interpretation framework commonly used for the generation of invariants.

The general idea of the preprocessor $p_{\text{invgen}}$ is the transformation of a program $P = ((\LSet, \TSet), \location_0, \PVSet, \TVSet, \cost)$ to a program $P' = ((\LSet, \TSet'), \location_0, \PVSet, \TVSet, \cost)$, such that if there is a transition $t = (\location, \update, \guard, \location')$ in $\TSet$, then there is also a transition $t' = (\location, \update, \guard \wedge \guard', \location')$ in $\TSet'$ such that every evaluation in the program $P$ is still an evaluation in the program $P'$.
The preprocessor $p_{\text{invgen}}$ affects the preprocessors $p_{\text{sat}}$, since an inferred invariant might make a transition guard unsatisfiable.

\subsection{Trivial time bounds}

For a program $\Program = ((\LSet, \TSet), \location_0, \VSet, \cost)$ the algorithm needs an initial time and size bound prior to the execution.
Obviously a time bound $\UTime$ with $\UTime(t) = \infty$ for all transitions $t \in \TSet$ is sound for all programs $\Program$.
Also an upper size bound $\USize$ with $\USize(\alpha) = \infty$ for all result variables $\alpha \in \RV$ and a lower size bound $\LSize$ with $\LSize(\alpha) = -\infty$ for all result variables $\alpha \in \RV$ are sound for all programs $\Program$.

For time bounds it is possible to infer a better time bound prior to the execution.
For all transitions $t \in \TSet$ which are not part of an SCC, we know, that they can only occur once in every evaluation.
Therefore, it is sound to use the initial time bound $\UTime$ with $\UTime(t) = 1$ for all transitions which does not occur in an SCC of the program $\Program$ and $\UTime(t) = \infty$ for all transitions which does occur in an SCC of the program $\Program$.

\subsection{Overall algorithm}

The last three chapters presented the theorems for the computation of time, size and cost bounds.
For the computation of a time bound of a whole program, it is necessary to define an algorithm, which consecutively uses the time and size bound theorems.
The computation of the cost bound can then be implemented as a post-processing step.

This section presents the implemented algorithm.
While the actual code is written in a functional style, the presented algorithm uses an imperative style to make the execution order explicit.

\begin{algorithm}
\caption{Inferring global time and cost bounds}\label{complete_algorithm}
\begin{algorithmic}[1]
  \State Input: A program $P = ((\LSet, \TSet),\location_0,\PVSet,\TVSet)$
  \State Run preprocessors
  \State Create a trivial time bound $\UTime$ and a trivial size bound $\Size$
  \State Compute local size bounds $\ULSB$ and $\LLSB$
  \State Construct the result variable graph RVG from $P$
  \State Compute a time ranking function for each transition in $\TSet$
  \State Compute a cost ranking function for each transition in $\TSet$
  \Repeat
    \ForAll{SCCs $\SCC$ of RVG in topological order}
      \State Run $\text{SizeBounds}(\UTime, \Size, \SCC)$
    \EndFor
    \ForAll{SCCs $\TSet'$ of $P$ in topological order}
      \ForAll{unbounded transitions $t \in \TSet'$}
        \State Run $\text{TimeBounds}(\UTime, \Size, \TSet', \braced{t})$
      \EndFor
    \EndFor
  \Until{all TimeBounds executions did not improve any time bound}
  \State Create a trivial cost bound $\UCost$
  \ForAll{transitions $t \in \TSet$}
    \State Run $\text{CostBounds}(\UTime, \Size, \TSet', \braced{t})$
  \EndFor
\end{algorithmic}
\end{algorithm}

\todo{Algorithm}{}

The algorithm takes a program as input and runs a sequence of preprocessors on it.
Then, it creates trivial time and size bounds, where each value is unbounded (i.e. $\infty, -\infty$).
For performance reasons, the computation of the local size bounds, the result variable graph, and the time and cost ranking functions is done before the actual computation of time, size and cost bounds.
Then, as long as the TimeBounds algorithm yields new time bounds, the SizeBounds algorithm and the TimeBounds algorithm are called.
When no more time bounds can be inferred, a trivial cost bound is created from the inferred time bounds and the CostBounds algorithm is executed for each transition to find a possibly better cost bound.

\subsection{Local size bound algorithm}

For the computation of size bounds we presented a definition of local size bounds in chapter six.
The implementation of an algorithm for the computation of local size bounds needs yield good local size bounds while providing good performance.

This section describes the implemented algorithm for the efficient computation of sound local size bounds $b^\sqcap \in \BoundSet^\sqcap_l$ and $b^\sqcup \in \BoundSet^\sqcup_l$.
We only consider the upper case, the implementation of the lower case is similar.
The main idea is to choose a candidate for an upper scaled sum and then use an SMT-Solver to prove its validity.
For a selected upper scaled sum $b \in \BoundSet^\sqcap_l$, the guard must imply for every state $\valuation$ that the upper scaled sum bounds the updated value of the variable.
\[ \forall \valuation \in \Valuation: \exacteval{\guard}{\valuation} \Rightarrow \exacteval{\update(v)}{\valuation} \leq \exacteval{b}{\valuation} \]
In general, an SMT-Solver is only able to find models for existential formulas $\exists v_0: \exists v_1: \dots \exists v_k: \phi(v_0, \dots, v_k)$. \cite{smt} \\
Therefore, we use the SMT-Solver to prove the unsatisfiability of the negation of the formula.
\[ \exists \valuation \in \Valuation: \exacteval{\guard}{\valuation} \wedge \exacteval{\update(v)}{\valuation} > \exacteval{b}{\valuation} \]
If the SMT-Solver proves unsatisfiability, the upper scaled sum is a sound overapproximation of the actual value of the variable $v$.

It remains to be shown, how to choose a candidate for an upper scaled sum.
Consider an upper scaled sum $b^\sqcap$.
\[ b^\sqcap = s \cdot \left(
e
+ \sum_{v \in P_1} v
- \sum_{v \in N_1} v
+ \sum_{v \in P_2} \maxO{v}
+ \sum_{v \in N_2} \maxO{-v}
\right)
\]

The algorithm analyzes the update and the guard of a transition to find overapproximated sound values for $s$ and $e$.
For each variable $v$ it holds that the upper scaled sum is bigger if $v \in P_2$ instead of $v \in P_1$.
The same holds for the sets $N_2$ and $N_1$.
Therefore the algorithm assigns the sets $P_1$ and $N_1$ the empty set in the beginning. 
Then, it loops through every variable set of the powerset of all program variables.
These are ordered with ascending cardinality, to try variable sets with fewer variables first.
This ensures that the resulting scaled sum is minimal in regard to the number of occurring variables.
If it found a valid scaled sum, it optimizes it in four steps.
In the first two steps minimize the constants $s$ and $e$.
The other two steps try to move variables from the sets $P_2$ and $N_2$ to their corresponding sets $P_1$ and $N_1$.

\begin{algorithm}
\caption{Inferring an upper scaled sum}\label{ulsb_algorithm}
\begin{algorithmic}[1]
  \State Input: A result variable $t = ((\location,\update,\guard,\location'),v) \in \RV$
  \State Set $s$ and $e$ to a sufficiently high value
  \State Set $P_1 := \emptyset$
  \State Set $N_1 := \emptyset$
  \ForAll {variable sets $\VSet \in 2^\PVSet$}
    \State Set $P_2 := \VSet$
    \State Set $N_2 := \VSet$
    \If {$\bigwedge \guard \Rightarrow \update(v) \leq b$ is valid}
      \State \textbf{break}
    \EndIf
  \EndFor
  \State Binary search $1 \dots s$ to find an $s$ such that $\bigwedge \guard \Rightarrow \update(v) \leq b$ is valid with this $s$, but not valid with $s-1$.
  \State Binary search $-e \dots e$ to find an $e$ such that $\bigwedge \guard \Rightarrow \update(v) \leq b$ is valid with this $e$, but not valid with $e-1$.
  \State Move variables from $P_2$ to $P_1$ such that $\bigwedge \guard \Rightarrow \update(v) \leq b$ is still valid
  \State Move variables from $N_2$ to $N_1$ such that $\bigwedge \guard \Rightarrow \update(v) \leq b$ is still valid
\end{algorithmic}
\end{algorithm}
