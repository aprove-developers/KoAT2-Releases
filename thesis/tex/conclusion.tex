\section{Conclusion}

This thesis presented a method for the computation of non-monotonic time, size and cost bounds of integer programs.
It is based on the method of \cite{koat} and extends it in several ways.

The main extension regards the computation of ranking functions for time bounds.
While the presented method uses the same approach to determine a ranking function as \cite{koat}, \cite{koat} applies an operator which transforms a non-monotonic rank into a monotonic rank.
The presented method uses an approximated substitution which substitutes each variable in regard to the monotonicity of the rank in this variable.
This way, a non-monotonic rank does not need to be transformed into a monotonic rank.

This change alone does not yield any benefit if the size bound used for the substitution of a variable is itself an upper size bound and its negation a lower size bound.
With this property of a size bound, an approximated substitution also transforms each non-monotonic rank into a monotonic rank.
Therefore, the presented method distinguishes between lower size bounds and upper size bounds.
It is able to use the difference between the positive and the negative effect of a variable.
The positive effect determines the upper size bound and the negative effect determines the lower size bound.
The opposite effect can be eliminated, respectively.
This way, the method yields more precise size bounds than \cite{koat}.
These are then used to infer more precise time bounds.

Another improvement concerns the computation of cost bounds.
This thesis presents an approach, where ranking functions are also used in the context of the costs of a program.
While time ranking functions yield a measure on the maximal number of steps possible from a specific location, cost ranking functions yield a measure on the maximal costs possible from a specific location.
With cost ranking functions, the presented method is able to infer more precise cost bounds.

The main benefit of the presented method is a more precise approximation of the coefficients of time and cost bounds.
But the method is also able to yield a better asymptotic complexity class.
This is, for example, the case if the lower size bound of a variable is approximated to be $0$ instead of the negation of the size bound computed by the method of \cite{koat}.

The described improvements and extensions of the presented method and the resulting performance in the evaluation against other comparable methods make the presented method a powerful tool for the computation of time and cost bounds of integer programs.

\subsection{Outlook}

While the presented method already produces acceptable results, there is still much room for further improvements.

One issue is the determination of the asymptotic complexity of the resulting non-monotonic bound.
The current implementation does not take into account, that a polynomial may only have a negative effect on a time bound.
Therefore, this polynomial may lead to a worse asymptotic complexity than the time bound actually is in.
The publication \cite{albert2009asymptotic} presents an approach to determine the asymptotic complexity of monotonic bounds which contain minimum and maximum operators.
Further work might extend this method to non-monotonic bounds, such that a better approximation of the asymptotic complexity of non-monotonic bounds might be found.
Besides that, an improvement of the used simplification algorithm of the presented implementation might also lead to a better approximation of the asymptotic complexity.

Another issue regards some common preprocessors.
While the cutting of unsatisfiable transitions and unreachable locations is beneficial for the performance and the results in all cases, other preprocessors need further configuration to be beneficial.

The implementation of the invariant generation produces all invariants of a specific domain.
While the analysis of the modified program certainly yields better or equal approximations, the performance may be heavily affected.
Furthermore, a different choice for the domain might lead to invariants resulting in a better approximation.
To improve the ratio between the effect on the result and the loss in performance, it might be interesting to consider an approach which only searches for specific invariants in cases where they are needed.

Another preprocessor which needs further configuration regards the chaining of transitions.
In some cases, a transition might be chained with all of its pre-transitions.
This way, new transitions leading from the starts of the pre-transitions to the target of the transition are created to replace the transition.
While chaining can lead to better approximations, in many cases it also leads to more transitions and though a loss in performance.
Further work might focus on a balanced configuration of chaining.

KoAT \cite{koat} implements a technique which unrolls single evaluation steps in a loop into own transitions in cases where no ranking function is found.
In general, this technique may not terminate since an infinite loop leads to an infinite number of unrolled transitions.
Nevertheless, an unrolling of a finite number of steps can lead to the computation of an otherwise not discovered ranking function.
Therefore, the application of this technique in the implementation might be beneficial.

Besides the possible implementation of these additional techniques, the actual method opens new possibilities.
Currently, the suitable ranking functions are chosen by the number of non-increasing transitions.
This is a heuristic to reduce the number of entry transitions and therefore to improve the quality of the approximations.
Further work might focus on improving this heuristic.
Furthermore, this method and \cite{koat} concentrate on the computation of a single local size bound for each result variable.
A heuristic is applied to reduce the constants and the number of variables, but the choice of local size bounds with the same number of variables is arbitrary.
This affects the SCCs of the result variable graph and therefore the method for the computation of size bounds.
Further work might want to study the effect of the choice of local size bounds on the resulting size bounds.
