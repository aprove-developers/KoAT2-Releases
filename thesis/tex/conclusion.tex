\chapter{Conclusion}

This thesis presented a method for the computation of non-monotonic time, size and cost bounds of integer programs.
It is based on the method of \cite{koat} and extends it in several ways.

The main extension regards the computation of ranking functions for time bounds.
While the presented method uses the same approach to determine a ranking function as \cite{koat}, \cite{koat} applies an operator which overapproximates a non-monotonic rank by a monotonic rank.
The presented method uses an approximated substitution which substitutes each variable in regard to the monotonicity of the rank in this variable.
This way, a non-monotonic rank does not need to be transformed into a monotonic rank.

This change alone does not yield any benefit if the size bound used for the substitution of a variable is itself an upper size bound and its negation a lower size bound.
With this property of a size bound, an approximated substitution also transforms each non-monotonic rank into a monotonic rank.
Therefore, the presented method distinguishes between lower size bounds and upper size bounds.
It is able to use the difference between the positive and the negative effect of a variable.
The positive effect determines the upper size bound and the negative effect determines the lower size bound.
The opposite effect can be eliminated, respectively.
This way, the method yields more precise size bounds than \cite{koat}.
These are then used to infer more precise time bounds.

Another improvement concerns the computation of cost bounds.
This thesis presents an approach, where ranking functions are also used in the context of the costs of a program.
While time ranking functions yield a measure on the maximal number of steps possible from a specific location, cost ranking functions yield a measure on the maximal costs possible from a specific location.
With cost ranking functions, the presented method is able to infer more precise cost bounds.

The main benefit of the presented method is a more precise approximation of the coefficients of time and cost bounds.
But the method is also able to yield a better asymptotic complexity class.
This is, for example, the case if the lower size bound of a variable is approximated to be $0$ instead of the negation of the size bound computed by \cite{koat}.

The described improvements and extensions of the presented method and the resulting performance in the evaluation against other comparable tools make the presented method a powerful tool for the computation of time and cost bounds of integer programs.

\section{Outlook}

While the presented method already produces acceptable results, there is still much space for further improvements.

One issue is the computation of the asymptotic complexity of the resulting non-monotonic bound.
Assume that the new method inferred a time bound $x-y^2$.
The longest evaluation might imply that $y$ is positive at the start of the program.
Then, the asymptotic complexity of the program is linear instead of quadratic.
But since this information is not captured, the complexity of the program is determined as quadratic.
Further work might focus on acquiring more information on the value of the variables at the start of the program to infer a better approximation of the asymptotic complexity.
Also, the publication \cite{albert2009asymptotic} presents an approach to determine the asymptotic complexity of monotonic bounds which contain minimum and maximum operators.
Further work might extend this method to non-monotonic bounds, such that a better approximation of the asymptotic complexity of non-monotonic bounds might be found.
Besides that, an improvement of the used simplification algorithm of the presented implementation might also lead to a better approximation of the asymptotic complexity.

Another issue regards some common preprocessors.
While the cutting of unsatisfiable transitions and unreachable locations is both beneficial for the performance and the results in every case, other preprocessors need further configuration to be beneficial.

The current implementation of the invariant generation produces invariants of a specific domain.
While an analysis of the program with added invariants always yields better or equal approximations, the performance might be heavily affected.
Furthermore, a different choice for the domain might result in invariants leading to a better approximation.
Also, to improve the ratio between the effect on the result and the loss in performance, it might be interesting to consider an approach which only searches for specific invariants in cases where they are needed.

Another preprocessor which needs further configuration regards the chaining of transitions.
In some cases, a transition might be chained with all of its pre-transitions.
This way, new transitions leading from the starts of the pre-transitions to the target of the transition are created to replace the transition.
While chaining can lead to better approximations, in many cases it also leads to more transitions and therefore a loss in performance.
Further work might focus on a balanced configuration of chaining.

KoAT \cite{koat} implements a technique which unrolls single evaluation steps in a loop into own transitions in cases where no ranking function is found.
In general, this technique may not terminate since an infinite loop leads to an infinite number of unrolled transitions.
Nevertheless, an unrolling of a finite number of steps can lead to the computation of an otherwise not discovered ranking function.
Therefore, the application of this technique in the implementation might be beneficial.

Besides the possible implementation of these additional techniques, the new method opens new possibilities.
Currently, the suitable ranking functions are chosen by the number of non-increasing transitions.
This is a heuristic to reduce the number of entry transitions and therefore to improve the quality of the approximations.
Further work might focus on improving this heuristic.
Furthermore, this method concentrates on the computation of a single local size bound for each result variable.
A heuristic is applied to reduce the constants and the number of variables, but the choice of local size bounds with the same number of variables is arbitrary.
This affects the SCCs of the result variable graph and therefore the method for the computation of size bounds.
Further work might want to study the effect of the choice of local size bounds on the resulting size bounds.
