\section{Computing size bounds}

In this chapter we will present the method, which is able to infer size bounds for the values of the variables at particular transitions of a program.


\subsection{Computing local size bounds}

\input{localsizebound}


\subsection{Computing trivial size bounds}

With the definition of local size bounds in the form of scaled sums, it is now possible to lift those local effects to a global level.
Instead of expressing the effect depending on the values immediately before a transition, we will now express the effect depending on the start values.

We first provide those global size bounds for trivial SCCs of the RVG.
Note that a node in the RVG is a result variable $\rv = (t,v) \in \RV$.
Trivial SCCs consist of a single node and they have the property that every evaluation passes the SCC only once.
In the graph this is recognizable through the fact, that no sequence of edges is leading back to the single node.

Again, we have to distinguish two cases.
If the transition $t$ of the result variable $\rv$ of the node is an initial transition $t \in \TSet_0$, then the effect of the local size bound already depends on the start values.
Thus, the local size bound for the result variable $\rv$ is also a global size bound.
If the transition $t$ is not an initial transition $t \notin \TSet_0$, then we have to substitute the variables of the local size bound by the global size bounds before entering the SCC.
The original KoAT uses monotonically increasing bounds for the local size bounds.
Therefore it is able to substitute every variable with a bound of the maximum absolute value obtained so far.
Since the defined scaled sums for local size bounds of the presented method are non-monotonic, it is necessary to split additional cases.
For scaled sums, we have monotonically increasing and monotonically decreasing components.
Let $\rv = (t,v) \in \RV$ be a result variable.
Then, the upper local size bound $\ULSB(\rv)$ and the lower local size bound $\LLSB(\rv)$ are monotonically increasing for each variable $v \in P_{\rv,1} \cup P_{\rv,2}$.
On the other hand for each variable $v \in N_{\rv,1} \cup N_{\rv,2}$ the upper local size bound $\ULSB(\rv)$ and the lower local size bound $\LLSB(\rv)$ are monotonically decreasing.

The redefined upper size bound ${\USize}'$ must be a sound overapproximation of the values of the variables.
Since upper size bounds $\USize$ overapproximate the value of variables and lower size bounds $\LSize$ underapproximate the value, it is sound to use the upper size bound $\USize$ for the substitution with the monotonically increasing variables and the lower size bound $\LSize$ for the substitution with the monotonically decreasing variables.

The redefined lower size bound ${\LSize}'$ must be a sound underapproximation of the values of the variables.
Therefore the upper size bound $\USize$ must be used for the substitution with the monotonically decreasing variables and the lower size bound $\LSize$ must be used for the substitution with the monotonically increasing variables.
The following definition formally introduces the computation of size bounds for trivial SCCs.

\input{theorems/trivial_sizebound}

We explain the presented method with an example.
Consider the program in figure \ref{fig:trivial_sizebound_example}.

\input{graphs/trivial_sizebound_example}

The program takes an arbitrary integer $x$ and an integer $y \leq 0$ and returns the variable $y$ unchanged, while it assigns the variable $x$ in both transitions a value depending on the incoming variables $x$ and $y$.
The result variable graph contains four trivial SCCs, each result variable forming an own SCC.
We now inspect the SCCs $\braced{(t_0,x)}$ and $\braced{(t_1,x)}$.

For the SCC $\braced{(t_0,x)}$ the transition $t_0$ is an initial transition.
We can determine a scaled sum $3 \cdot (1 + \maxO{x} - y)$ as upper local size bound $\ULSB(t_0,x)$ and a scaled sum $2 \cdot x$ as lower local size bound $\LLSB(t_0,x)$.
Since we have $\USize'(t_0,x) = \ULSB(t_0,x)$ and $\LSize'(t_0,x) = \LLSB(t_0,x)$, the determined local size bounds are also global size bounds.

For the SCC $\braced{(t_1,x)}$ the transition $t_1$ is not an initial transition.
Therefore the local size bound expresses the values of the variables in terms of their value immediately before the execution of $t_1$.
For the computation of the global size bounds we need to substitute these variables with the global size bound obtained so far until the execution of $t_1$.
We already inferred those size bounds $\USize(t_0,x)$ and $\LSize(t_0,x)$ for the single transition $t_0$ leading to $t_1$.
Additionally, we can trivially infer the size bounds $\USize(t_0,y) = y$ and $\LSize(t_0,y) = y$.
We can also determine a scaled sum $3 \cdot (\maxO{-x} + y)$ as upper local size bound $\ULSB(t_1,x)$ and a scaled sum $3 \cdot (-1 - \maxO{x} + y)$ as lower local size bound $\LLSB(t_1,x)$.
For the result variable $\rv = (t_0,x)$ the parameters of the upper local size bound are $s^\sqcap_\rv = 3$, $e^\sqcap_\rv = 0$, $N^\sqcap_{\rv,2} = \braced{x}$, $P^\sqcap_{\rv,1} = \braced{y}$ and $P^\sqcap_{\rv,2} = N^\sqcap_{\rv,1} = \emptyset$ and the parameters of the lower local size bound are $s^\sqcup_\rv = 3$, $e^\sqcup_\rv = -1$, $N^\sqcup_{\rv,2} = \braced{x}$, $P^\sqcup_{\rv,1} = \braced{y}$ and $P^\sqcup_{\rv,2} = N^\sqcup_{\rv,1} = \emptyset$.
For a sound approximation it is necessary to substitute the variables with the correct incoming bounds depending on whether we want to infer an upper or lower bound and whether the sign of the variable is positive or negative.
The resulting global upper size bound $\USize'(t_0,x)$ therefore is 
\begin{align*}
  && 3 \cdot ( 0 + \USize(t_0, y) - 0 + 0 + \maxO{-\LSize(t_0, x)} ) \\
  & = & 3 \cdot ( y + \maxO{-2 \cdot x} )
\end{align*}
The resulting global lower size bound $\LSize'(t_0,x)$ we can determine as
\begin{align*}
  && 3 \cdot ( -1 + \LSize(t_0, y) - 0 + 0 + \maxO{-\USize(t_0, x)} ) \\
  & = & 3 \cdot ( -1 + y + \maxO{3 \cdot (1 + \maxO{x} - y)} )
\end{align*}


\subsection{Computing nontrivial size bounds}

In the last section we presented a method SizeBounds to infer upper and lower size bounds for result variables $\rv \in \RV$ which form a trivial SCC $\braced{\rv}$.
In this section, we extend the method to infer upper and lower size bounds for nontrivial SCCs.

Prior to the definition of the method, we need to define three utility definitions also used by the original KoAT.

First, we define the pre-variables of a result variable $\rv \in \RV$ as an overapproximation $\pre(\rv) \subseteq \RV$ of all the result variables that directly affect the value of a result variable $\rv \in \RV$.
This is a similar definition to the pre-transitions of a transition, but acting on the result variable graph instead of the program graph.
Since the result variable graph represents the information about which result variables affect each other, the predecessors of a result variable in a result variable graph are a valid implementation of the function $\pre$.

Additionally, we define the scc-variables $\VSet_\rv = \braced{ v \mid \exists (t, v) \in \pre(\rv) \cap \SCC }$ of a result variable as those variables, which affect the result variable from within the SCC of the result variable graph.
For those variables we know, that their value is mutated throughout a loop.

The third definition $\SCC_t$ selects from an SCC $\SCC$ of the result variable graph those result variables $\SCC_t = \braced{(t,v) \mid \exists v \in \VSet : (t,v) \in \SCC}$, that use a specific transition $t$.

\todo{Examples for utilities}{}

Now we are able to extend the method SizeBounds to nontrivial size bounds.

\input{theorems/nontrivial_sizebound}

The definition is similar to the method presented by the original KoAT, but extends it to the usage of upper and lower bounds.
The overall idea is, to define a maximal \textbf{starting value} $\start$ and accumulate the maximal effects of all transitions within the SCC $\SCC$.
When we refer to an effect of a transition, we mean the change of a value by a single occurrence of a transition in an evaluation.
We distinguish between positive and negative effects.
A positive effect increases the value of a variable, while a negative effect decreases the value of a variable.
Although we refer to them as positive and negative, both types of effects reflect the absolute value by which the variable increases/decreases.
It is easy to see, that for the computation of an upper size bound, it is necessary to capture all positive effects, while for the computation of lower size bounds, it is necessary to capture all negative effects.
The capturing of negative effects for the computation of upper size bounds and positive effects for the computation of lower size bounds would lead to better bounds, but in practice this is not achievable.
For the valid overapproximation of negative effects for upper size bound, it would be necessary to approximate the accumulation of those negative effects with the lower time bound.
\todo{Source?}{But related work agrees, that it is not possible to effectively compute lower time bounds.}
Therefore, in any case which could yield a negative effect (or a positive effect for a lower size bound), we annihilate the effect to $0$.

We now analyze the new method in three steps to explain the reasoning behind the different components of the method.
First, we analyze the upper case in detail.
Then, we explain the differences with the lower case.
In the first step, we consider a program, that multiplies a single variable in a loop with a factor, but does not depend on other variables.
In the second step, we consider a program, that adds iteratively another variable to a variable, but does not use a multiplication with a factor.
As we will see, those are corner cases of the general size bound definition.
\[ {\mathcal{S}^\sqcap}'(\beta) = \scale^\sqcap_\SCC \cdot \left( \start + \effect^\sqcap_\SCC \right) \]
For the first program this definition will break down to ${\mathcal{S}^\sqcap}'(\beta) = \scale^\sqcap_\SCC \cdot \left( \start + 0 \right)$.
For the second program this definition will break down to ${\mathcal{S}^\sqcap}'(\beta) = 1 \cdot \left( \start + \effect^\sqcap_\SCC \right)$.
In a third step, we then present a more complex program, which does not fall in those corner cases.

\subsubsection{Step One: Internal multiplication}

Consider again the example program from the introduction in figure \ref{fig:nontrivial_nodependency}.

\input{graphs/nontrivial_nodependency}

It starts with a value for the variable $y$ and multiplies the value of $y$ in a loop $t_1$ with $-2$.
The value of $y$ therefore switches between negative and positive extrema in a sequence $y, -2 \cdot y, 4 \cdot y, -8 \cdot y, 16 \cdot y, \dots$.
Thus, the value of $y$ after the loop $t_1$ does only depend on the value of $y$ after the transition $t_0$ and the value of $y$ after previous steps of the loop $t_1$.
The idea is, that we start with an overapproximation of the initial value of $y$ before entering the loop and then multiply it with the maximal factors inside the loop.

The overapproximation of the initial value of $y$ is reflected by the \textbf{starting value}.
\[ \start = \maximum{\max(\USize(\prerv), -\LSize(\prerv)) \mid \exists \rv \in \SCC: \prerv \in \pre(\rv) \setminus \SCC} \]
We consider all result variables, which might affect the value of $y$ and select the maximal value among them.
One might initially think, that it is sufficient, to consider a different starting value.
\[ \start = \maximum{\USize(\prerv) \mid \exists \rv \in \SCC: \prerv \in \pre(\rv) \setminus \SCC} \]
But this starting value is not sound.
The reason is, that we are not able to predict the exact number of occurrences of a transition, since we only have a bound.
In the example, we have the time bound $\UTime$ with $\UTime(t_1) = x$.
The time bound $\UTime$ represents the maximum number of occurrences of a transition within an evaluation, but in the example program it would be necessary to have more information than just a bound.
The actual number of occurrences of $t_1$ in an evaluation could also be $x-1$, which yields a much different size for the variable $y$.
Therefore, in general it is necessary to consider the highest absolute incoming value as starting value.
For the example, this results in the starting value $\start = \max(x, -x)$.
Note that $\start$ is greater than $0$ by definition, since for all result variables $\rv \in \RV$ it holds that $\USize(\rv) \geq \LSize(\rv)$ and therefore either $\USize(\rv)$ or $-\LSize(\rv)$ is positive or equal to $0$.

Additionally to the starting value, we have to consider the factors mutating the starting value during the loop $t_1$.
Intentionally, we can see, that with each occurrence of the transition $t_1$ the upper size bound increases by the factor $2$.
After $\UTime(t_1)$ occurrences of $t_1$, the value of $y$ is at most $2^{\UTime(t_1)} \cdot \start$.
This is covered by the \textbf{loop scaling factor} $\scale^\sqcap_\SCC$.
It consists of the multiplication of all the \textbf{transition scaling factors} $\scale^\sqcap_t$ of the transitions $t \in \TSet_\SCC$ of the SCC $\SCC$.
For the example, there is only one transition in the SCC, therefore the loop scaling factor reduces to the exponentiation with a single transition scaling factor $(\scale^\sqcap_{t_1})^{\UTime(t_1)}$.
Since the scaling factor of the local size bound of the result variable $(t_1,y) \in \SCC$ is $2$ and $(t_1,y)$ is the only result variable of the SCC $\SCC$, $2$ is also the maximal scaling factor $\maximum{s^\square_{\rv} \mid \rv \in \SCC_t}$ for the transition $t$ in the SCC $\SCC$.
This results in the expected upper size bound $2^{\UTime(t_1)} \cdot \start$ for the result variable $(t_1,y)$.

There are two parts, which still need to be covered, before we can be sure, that $2^{\UTime(t_1)} \cdot \start$ is actually the result of ${\mathcal{S}^\sqcap}'(t_1,y)$.
The first part is the \textbf{loop effect} $\effect^\sqcap_\SCC$, which we assumed to be $0$ in the example.
This is non-obvious, since we have a sum over the non-empty set $\TSet_\SCC = \braced{t_1}$.
The reason for $\UTime(t_1) \cdot \effect^\sqcap_{t_1}$ to be $0$ has two reasons.
One reason is, that the constant $e^\sqcap_{(t_1,y)}$ of the local size bound of $(t_1,y)$ is $0$.
The other reason is, that the local size bound of the result variable $(t_1,y) \in \SCC$ only depends on the variables $\VSet_{(t_1,y)} = \braced{y}$, that are manipulated during the loop.
We can exclude those variables from the \textbf{result variable effect} $\effect^\sqcap_{(t_1,y)}$, because we consider them in another part of the definition.

This leads us, to the second part, which we did not cover yet.
This is the factor $\maximum{\abs{V_\rv} \mid \rv \in \SCC_t}$, which was not yet mentioned, but is part of the \textbf{transition scaling factor} $s^\sqcap_t$.
In the example this part of the transition scaling factor is $1$, but in general it can be a number greater than $1$.
This factor reflects, that exponential bounds can not only result from scaling factors which are greater than $1$, but also from variables, which affect each other consecutively in a loop.
Consider the example in figure \ref{fig:exp_with_vars}.

\input{graphs/exp_with_vars}

The program has three variables $x$, $y$ and $z$.
The variable $x$ determines the number of runs of the loop $t_1$.
With each run of the transition $t_1$ the value of $y$ increases by the value of $z$ (or decreases for $z < 0$).
The value of $z$ is set in each step of the loop to the previous value of $y$.

Let $(a,b,c)$ be a notation for a state $\valuation \in \Valuation$ with $\valuation(x) = a$, $\valuation(y) = b$ and $\valuation(z) = c$.
Then, for starting values $x$, $y$ and $z$, we can define a possible evaluation.
\begin{align*}
  (\location_0, (x,1,1)) & \rightarrow_{t_0} (\location_1, (x,1,1)) \\
  & \rightarrow_{t_1} (\location_1, (x-1,2,1)) \\
  & \rightarrow_{t_1} (\location_1, (x-2,3,2)) \\
  & \rightarrow_{t_1} (\location_1, (x-3,5,3)) \\
  & \rightarrow_{t_1} (\location_1, (x-4,8,5)) \\
  & \rightarrow_{t_1} (\location_1, (x-5,13,8)) \\
  & \rightarrow_{t_1} \dots
\end{align*}
We can observe, that the variables $y$ and $z$ enumerate the fibonacci numbers.
They affect each other in the loop and as a result their value is not bounded by a polynomial.

Since the fibonacci sequence can not be represented with the bound set $\BoundSet$, it is necessary to use an overapproximation.
Lets consider the update $\update(y) = y + z$.
We have a non-polynomial bound, because the incoming values of $y$ and $z$ can change during the loop $t_1$.
For this reason they are part of the set $\VSet_{(t_1,y)} = \braced{y,z}$.
The idea of the factor $\maximum{\abs{V_\rv} \mid \rv \in \SCC_t}$ is, that we can overapproximate the effect of $\update(y)$ with $2 \cdot \max(y,z)$.
This bound is representable in the bound set $\BoundSet$. 

\subsubsection{Step Two: Dependency on outside variables}

The second component, we consider, is the addition with constant values from outside of the SCC $\SCC$.
Consider the program in figure \ref{fig:additive_loop}.

\input{graphs/additive_loop}

The program is very similar to the program in figure \ref{fig:exp_with_vars}.
The difference is, that the value of $z$ does not depend on the value of $y$ anymore.
Instead, the value of $z$ is constant throughout the loop $t_1$.
The consequence is, that the update $\update(y) = y + z$ can not result in exponential growth anymore, since the variables mutated during the loops are $V_{(t_1,y)} = \braced{y}$ instead of $\braced{y,z}$.
Therefore, we can find a better bound than an exponential bound, if we consider the update $\update(y) = y + z$ to be an addition of $y$ with a constant $z$.

We now want to determine a size bound for the variable $y$ after the transition $t_1$.
The result variable graph shows, that the value of $y$ affects itself in the loop $t_1$, while it also depends on the value of $y$ after the transition $t_0$ and the value of $z$ after the transitions $t_0$ and $t_1$.
The \textbf{starting value} $\start$ is $\maximum{y,-y,z,-z}$.
Now, we must approximate the effect of the addition of the value of $z$ in each step of the loop $t_1$.
If $z$ is negative, then each iteration of the loop decreases the value of $y$ and therefore the starting value is an upper size bound.
Since we do not have a lower time bound, it is not possible to utilize this decrease to find a better upper size bound.
On the other hand, if $z$ is positive, then each iteration of the loop increases the value of $y$ and therefore we can approximate the increase by the upper time bound $\UTime(t_1)$ multiplied with the effect $z$.
For lower size bounds this logic is contrary.
If $z$ is negative, then each iteration of the loop decreases the value of $y$ and therefore, in contrast to the definition of upper size bounds, we can approximate the decrease by the upper time bound $\UTime(t_1)$ multiplied with the effect $z$.
If $z$ is positive, we can infer the starting value as lower size bound.

Note that for an update $\update(y) = y - z$ for the transition $t_1$, we need an additional case distinction, since the different sign also flips the presented logic.
This is all reflected in the definitions of the \textbf{transition effects} $\effect^\sqcap_t$ and $\effect^\sqcup_t$.
While the positive transition effect $\effect^\sqcap_t$ describes a bound for the upper case, the negative transition effect $\effect^\sqcup_t$ describes a bound for the lower case.
In the example program, we have to consider the transition effect $\effect^\sqcap_{t_1}$ of the transition $t_1$ for the computation of the upper size bound.
For this purpose, we need to consider the maximal \textbf{result variable effects} of all result variables in the SCC $\SCC$ which use the transition $t_1$.
We only consider the maximal effect, because a transition effect reflects exactly one step with the transition $t$.
\todo{Example with multiple rvs}{In the example, there is only one result variable $(t_1,y) \in \SCC$, which uses the transition $t_1$.}
Therefore, we have $\effect^\sqcap_{t_1} = \effect^\sqcap_{(t_1,y)}$.

\todo{Continue}{}

\subsubsection{Step Three: All together}

\todo{Useful?}{}
