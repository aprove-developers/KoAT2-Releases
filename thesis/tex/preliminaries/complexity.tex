\subsection{Complexity}

In this section we define the terms of time, size and cost complexity.
Time complexity describes how many steps an evaluation of a program will take in a worst-case scenario.
The costs of a transition are not considered in this complexity type.
On the other hand cost complexity considers the costs of transitions and describes the cost of the sequence of transitions taken in a worst-case run.
The third complexity type we need is size complexity.
Size complexity yields for each transition an assignment \todo{Correct?}{from each variable to its maximum value} after the execution of the transition in an arbitrary run.

\subsubsection{Time Complexity}

We define the time complexity of a program $\Program$ as the highest number of steps possible in an arbitrary run with an arbitrary initial state $\abs{\valuation_0} \in \Valuation$.

\begin{definition}[Worst-Case Time Complexity]
  We call $\text{rc} \in \BoundSet$ the time complexity of a program if and only if for all initial states $\valuation_0 \in \Valuation$ it holds that
  \[ \eval{\text{rc}}{\valuation_0} = \sup \braced{ k \in \mathbb{N} \mid \exists \location, \valuation: (\location_0, \valuation_0) \rightarrow^k (\location, \valuation) } \]
\end{definition}

This definition is slightly different than in related work. \todo{Source needed?}{}
Often time complexity is considered to be a function which is monotonic in its input state $\eval{\text{rc}'}{m} = \sup \braced{ k \in \mathbb{N} \mid \exists \valuation_0, \location, \valuation: \abs{\valuation_0} \leq m \wedge (\location_0, \valuation_0) \rightarrow^k (\location, \valuation) }$.
This guarantees that for a input $m \in \Valuation$ there is no other input $m' \leq m$ with $\eval{\text{rc}'}{m'} > \eval{\text{rc}'}{m}$.
Unfortunately, this property can not be guaranteed anymore with non-monotonic bounds.
Consider the motivational program in figure \ref{fig:motivational_example} and a input state $m \in \Valuation$ with $m(x) = 4$ and $m(y) = 2$.
The time complexity according to the definition in related work would then be $\eval{\text{rc}'}{m} = 7$, since with a state $\valuation_0 \in \Valuation$ with $\valuation_0(x) = 4$ and $\valuation_0(y) = -2$ we have one occurrence of $t_0$ and six occurrences of $t_1$.
As mentioned before, the new method should be able to yield a time bound $1 + \maxO{x-y}$.
But for the defined input state $m \in \Valuation$ this would yield $1 + \maxO{4-2} = 3$, which would be unsound according to the definition of time complexity.
With the changed definition the time complexity is $\eval{\text{rc}}{m} = 1 + 2$.
Therefore the non-monotonic bound is sound according to this definition.

\begin{definition}[Upper Time Bound]
  We call $\UTime: \TSet \rightarrow \BoundSet$ a time bound if and only if for all $t \in \TSet$ and all initial states $\valuation_0 \in \Valuation$ it holds that
  \[ \eval{\UTime(t)}{\valuation_0} \geq \sup \braced{ k \in \mathbb{N} \mid \exists \location, \valuation: (\location_0, \valuation_0) (\rightarrow^* \circ \rightarrow_t)^k (\location, \valuation) } \]
\end{definition}

\begin{theorem}[Approximating Time Complexity]
	Let $\UTime$ be a time approximation for $\TSet$.
	Then it holds that 
	\[ \mathit{rc} \leq \sum_{t \in \TSet}\UTime(t) \]
\end{theorem}

\subsubsection{Cost Complexity}

\begin{definition}[Worst-Case Cost Complexity]
\[ \eval{\text{cc}}{m} = \sup \braced{ \sum_{0 \leq i \leq k} \eval{\cost(t_i)}{\valuation_i} \mid \exists k \geq 1, \valuation_0, \location, \valuation: \abs{\valuation_0} \leq m \wedge
  (\location_0, \valuation_0) \rightarrow_{t_0} (\location_1, \valuation_1) \rightarrow_{t_1} \dots \rightarrow_{t_k} (\location_k, \valuation_k) } \]
\end{definition}

\begin{definition}[Upper Cost Bound]
  Let $\abs{\mathcal{S}}(t, v)$ denote highest absolute value $\max(\USize(t, v), -\LSize(t, v))$ a variable $v$ can reach at a transition $t$.
  We call $\UCost: \TSet \rightarrow \BoundSet$ a cost bound if and only if for all $t \in \TSet$ it holds that
  \[ \UCost(t) =
  \begin{cases}
    \UTime(t) \cdot \maxO{\cost(t)} & \text{if } t \text{ is an initial transition} \\
    \UTime(t) \cdot \maxO{\maximum{\eval{\cost(t)_+}{\USize(\tilde{t})} - \eval{\cost(t)_-}{\LSize(\tilde{t})} \mid \tilde{t} \in \pre(t)}} & \text{if } \cost(t) \text{ is an affine polynomial} \\
    \UTime(t) \cdot \maxO{\maximum{\eval{\abs{\cost(t)}}{\abs{\mathcal{S}}(\tilde{t})} \mid \tilde{t} \in \pre(t)}} & \text{otherwise} \\
  \end{cases}
  \]
\end{definition}

\begin{theorem}[Approximating Cost Complexity]
	Let $\UCost$ be a cost approximation for $\TSet$.
	Then it holds that 
	\[ \mathit{cc} \leq \sum_{t \in \TSet} \UCost(t) \]
\end{theorem}

\subsubsection{Size complexity}

A size bound of a program defines for each variable at a particular transition an interval in which the value ranges in a worst-case evaluation.
An interval is defined by a lower size bound and an upper size bound.
While upper size bounds are always higher than the highest possible value at a transition, lower size bounds are always smaller than the lowest possible value.

\begin{definition}[Worst-Case Size Bound]
  We call $\USize: \RV \rightarrow \BoundSet$ an \textbf{upper} size bound if and only if for all $(t, v) \in \RV$ and all \todo{Correct, not to use m here?}{$\valuation \in \Valuation$} it holds that
  \[ \eval{\USize(t, v)}{\valuation_0} \geq \sup \braced{\valuation(v) \mid \exists \location, \valuation: (\location_0, \valuation_0) (\rightarrow^* \circ \rightarrow_t) (\location, \valuation)}. \]
  Furthermore, we call $\LLSB: \RV \rightarrow \BoundSet$ a \textbf{lower} size bound if and only if for all $(t, v) \in \RV$ and all $\valuation$ it holds that
  \[ \eval{\LSize(t, v)}{\valuation_0} \geq \inf \braced{\valuation(v) \mid \exists \location, \valuation: (\location_0, \valuation_0) (\rightarrow^* \circ \rightarrow_t) (\location, \valuation)}. \]
  We call $\Size$ a size bound.
\end{definition}

Note that for a transition $t = (\location,\text{id},\guard,\location') \in \TSet$, the upper size bound $\USize(t,x) = x$ is identical to the lower size bound $\LSize(t,x) = x$.
We have different upper and lower size bounds if we have further restrictions on the incoming variables.
With $\guard = \braced{x \geq 0}$ we can determine $\USize(t,x) = x$ as an upper bound and $\USize(t,x) = 0$ as a lower bound.

The presented definition of size bounds expresses a bound depending on the values at the start of the program.
For the definition of the methods for the computation of trivial and nontrivial size bounds we also need a definition of bounds depending on the values immediately before the execution of a transition.
We then use those local size bounds to lift them in higher contexts like the whole program.

\begin{definition}[Local Sizebound]
  We call $\ULSB: \RV \rightarrow \BoundSet$ an \textbf{upper} local size bound if and only if for all $(t, v) \in \RV$ and all \todo{Correct, not to use m here?}{$\valuation$} it holds that
  \[ \eval{\ULSB(t, v)}{\valuation} \geq \sup \braced{\valuation'(v) \mid \exists \valuation': \valuation \rightarrow_t \valuation'}. \]
  Furthermore, we call $\LLSB: \RV \rightarrow \BoundSet$ a \textbf{lower} local size bound if and only if for all $(t, v') \in \RV$ and all $\valuation$ it holds that
  \[ \eval{\LLSB(t, v)}{\valuation} \geq \inf \braced{\valuation'(v) \mid \exists \valuation': \valuation \rightarrow_t \valuation'}. \]
  We call $\LSB$ a local size bound.
\end{definition}

\todo{Example for the difference between local and global}
